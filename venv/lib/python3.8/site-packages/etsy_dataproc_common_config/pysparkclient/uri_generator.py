from google.cloud import storage
import os
import random
import string
import semver
import functools
from etsy_dataproc_common_config.util import retry

class URIGenerator(object):
    GCS_BUCKET_MASTER = "pyspark-build-artifacts-47no"
    GCS_BUCKET_BRANCH = "pyspark-autodeleted-branch-build-artifacts-ltk4"

    def __init__(self,
            repo,
            package_name,
            branch,
            major_version,
            patch_version,
            bucket_name,
            staging_bucket_name
            ):

        self.repo = repo
        self.package_name = package_name
        self.branch = branch
        self.major_version = major_version
        self.patch_version = patch_version
        self.bucket_name = bucket_name if bucket_name else self._get_default_bucket_name(branch)
        self.staging_bucket_name = staging_bucket_name
        self.latest_version = None

    def _get_default_bucket_name(self, branch):
        if branch == "master":
            return URIGenerator.GCS_BUCKET_MASTER
        else:
            return URIGenerator.GCS_BUCKET_BRANCH

    def _get_prefix(self):
        return "{}/{}/{}/".format(self.repo, self.branch, self.package_name)

    def _check_valid_version(self, version):
        sc = storage.Client()
        bucket = storage.Bucket(sc, name=self.bucket_name)
        return isinstance(bucket.get_blob("{}{}/_SUCCESS".format(self._get_prefix(), version)), storage.Blob)

    def _get_version_from_path(self, path):
        # retrieves path after prefix and removes backslash from remaining path
        # isolates the version (e.g. '0.3.45') from 'gs://sample_bckt/sample_path/0.3.45/sample.py'
        prefix = self._get_prefix()
        ver = os.path.relpath(path, prefix).rstrip('/')
        try:
            # checks if _SUCCESS file exists in directory (indicates that the version was successfully created)
            if not self._check_valid_version(ver):
                return None
            # ensures that the remaining strings are semver strings
            # if a major_version is specified, it also filters out versions whose major doesn't match
            sem_version = semver.parse(ver)
            if self.major_version is not None:
                if int(sem_version['major']) == int(self.major_version):
                    return ver
                return None
            else:
                return ver
        except ValueError:
            return None

    @retry(Exception)
    def _get_versions_from_gcs(self):
        sc = storage.Client()
        bucket = storage.Bucket(sc, name=self.bucket_name)
        if self.major_version is not None:
            iterator = bucket.list_blobs(prefix=self._get_prefix()+str(self.major_version), delimiter="/")
        else:
            iterator = bucket.list_blobs(prefix=self._get_prefix(), delimiter="/")

        versions = set()
        for page in iterator.pages:
            for ver_path in page.prefixes:
                # checks if _SUCCESS file exists in directory (indicates that the version was successfully created)
                check_valid_blob = storage.Blob(ver_path+'_SUCCESS', bucket)
                if check_valid_blob.exists():
                    # retrieves path after prefix and removes backslash from remaining path
                    # isolates the version (e.g. '0.3.45') from 'gs://sample_bckt/sample_path/0.3.45/sample.py'
                    prefix = self._get_prefix()
                    version = os.path.relpath(ver_path, prefix).rstrip('/')
                    versions.add(version)

        return versions

    def _get_latest_version_gcs(self):
        """
        Retrieve the latest git tag version using gsutil ls on GCS.

        self: self object
        type: URIGenerator

        return latest version on GCS
        type: str
        """
        if self.latest_version is not None:
            return self.latest_version

        prefix = self._get_prefix()

        # get versions from the specified prefix
        versions = list(self._get_versions_from_gcs())

        if len(versions) == 0:
            if self.major_version:
                raise ValueError("No matching versions for major version {} under the {} directory. It's possible that a _SUCCESS file is missing under these subdirectory.".format(self.major_version, prefix))
            raise ValueError("No valid versions under the {} directory. It's possible that a _SUCCESS file is missing for versions under these subdirectories.".format(prefix))

        if len(versions) == 1:
            return versions[0]

        # retrieves the latest version and caches the value for any subsequent calls
        self.latest_version = functools.reduce(lambda x,y: semver.max_ver(x, y), versions)

        return self.latest_version

    def _get_version(self):
        if self.major_version is not None and self.patch_version is not None:
            version = '{}.0.{}'.format(self.major_version, self.patch_version)
            if self._check_valid_version(version):
                return version
            raise Exception("package upload is not complete. {} is missing _SUCCESS file".format(version))

        version = self._get_latest_version_gcs()

        return version

    def _get_random_str(self):
        return '_' + ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(4))

    def _randomize_file_name(self, file_name):
        random_str = self._get_random_str()
        file_prefix, sep, file_ext = file_name.partition(".")
        return "{}{}{}{}".format(file_prefix, random_str, sep, file_ext)

    def get_archive_file_and_alias(self, archive):
         # Separates the archive file name from the given alias
         file_name, _, alias = archive.partition("#")
         if alias is not '': alias = '#' + alias
         return file_name, alias

    def get_artifact_uri(self, artifact_name):
        if self.branch == "master":
            version = self._get_version()
            artifact_uri = os.path.join('gs://', self.bucket_name, self.repo, self.branch, self.package_name, version, artifact_name)
        else:
            artifact_uri = os.path.join('gs://', self.bucket_name, self.repo, self.branch, self.package_name, artifact_name)

        return artifact_uri

    def upload_file_to_staging_bucket(self, local_artifact, artifact_type):
        """
        Uploads a local file to the GCS staging bucket. Also adds a random suffix.

        self: self object
        type: URIGenerator

        return: gcs path of local file that has been uploaded
        type: str
        """
        # Checks if local file path exists
        if os.path.exists(local_artifact) == False:
            raise OSError('provided file path: {} does not exist.'.format(local_artifact))

        storage_client = storage.Client()

        bucket = storage_client.get_bucket(self.staging_bucket_name)

        # Adds a 4 digit random alphanumeric suffix to file name on GCS
        #TODO: define staging path somewehre
        artifact_path = "{}/{}".format(artifact_type, self._randomize_file_name(os.path.basename(local_artifact)))
        artifact_blob = bucket.blob(artifact_path)
        artifact_blob.upload_from_filename(local_artifact)

        # Returns full GCS path of the staged file
        return "gs://" + os.path.join(bucket.name, artifact_blob.name)
