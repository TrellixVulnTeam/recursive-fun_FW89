from stallion.schemas.base import StrictSchema, PermissiveSchema
from stallion.schemas.data_lake import DataLakeMetadataSchema, DataLakePropertiesSchema
import marshmallow as ma


class DataprocSchema(PermissiveSchema):
    region = ma.fields.String(required = True)
    zone = ma.fields.String(required = True, allow_none=True)
    image_version = ma.fields.String(required = True)
    dataproc_custom_image_for_pyspark = ma.fields.String()

    master_machine_type = ma.fields.String(required = True)
    master_disk_size_gb = ma.fields.Integer(required = True)

    num_workers = ma.fields.Integer(required = True)
    num_preemptible_workers = ma.fields.Integer()
    worker_machine_type = ma.fields.String(required = True)
    worker_disk_size_gb = ma.fields.Integer(required = True)
    autoscaling_policy = ma.fields.String()

    canonical_data_bucket = ma.fields.String(required = True)
    canonical_service_account = ma.fields.String()

    default_data_bucket = ma.fields.String(required = True)
    default_service_account = ma.fields.String(required = True)

    data_lake_bucket = ma.fields.String(required = False)
    visits_data_lake_bucket = ma.fields.String(required = False)

    logs_bucket = ma.fields.String()

    # Note: we are transitioning from using the default_network_uri argument,
    # which was not actually even used, to the default_subnetwork_uri argument,
    # which is used.
    default_network_uri = ma.fields.String()
    default_subnetwork_uri = ma.fields.String()
    default_network_tags = ma.fields.List(ma.fields.String(), missing = [])

    use_vpc = ma.fields.Boolean(missing = False)
    sharedvpc_subnetwork_uri = ma.fields.String()
    sharedvpc_network_tags = ma.fields.List(ma.fields.String())
    dns_init_script_uri = ma.fields.String()

    idle_delete_ttl_sec = ma.fields.Integer()
    auto_delete_ttl_sec = ma.fields.Integer()

    jupyter_notebook_bucket = ma.fields.String()

    spark_application_history_location = ma.fields.String()

    spark_cluster_key_prefix = ma.fields.String()

    use_data_lake = ma.fields.Boolean(missing = False)
    cloud_sql_proxy_init_script_uri = ma.fields.String()
    data_lake_metadata = ma.fields.Nested(DataLakeMetadataSchema)
    data_lake_properties = ma.fields.Nested(DataLakePropertiesSchema)
